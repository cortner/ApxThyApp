{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA3J8 Approximation Theory and Applications \n",
    "\n",
    "## 03 - Algebraic Polynomials\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using SoftGlobalScope, LinearAlgebra, LaTeXStrings, Plots\n",
    "gr();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-1 - Runge's Phenomenon\n",
    "\n",
    "We consider the function $f : [-1, 1] \\to \\mathbb{R}$, \n",
    "$$\n",
    "   f(x) = \\frac{1}{1 + 25 x^2}\n",
    "$$\n",
    "Note that $f$ is analytic on $[-1,1]$, hence from our work on trigonometric approximation we expect excellent approximation properties. We choose a uniform grid, \n",
    "$$\n",
    "  x_j = -1 + 2j/N, \\qquad j = 0, \\dots, N\n",
    "$$\n",
    "and interpolate $f$ at those grid points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Polynomials\n",
    "f(x) = 1 / (1 + 25 * x^2)\n",
    "N = 10\n",
    "X = range(-1, stop=1, length=N)\n",
    "p = polyfit(X, f.(X))\n",
    "xp = range(-1, stop=1, length=200)\n",
    "plot(xp, f.(xp), lw=2, label = \"f\")\n",
    "plot!(xp, p.(xp), lw=2, label = \"p$N\")\n",
    "plot!(X, f.(X), lw=0, m=:o, ms=6, c=2, label = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this does not look great. Maybe we just aren't using enough points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = range(-1, stop=1, length=400)\n",
    "P = plot(xp, f.(xp), lw=2, label = \"f\")\n",
    "for N in [10, 20, 30]\n",
    "    X = range(-1, stop=1, length=N)\n",
    "    p = polyfit(X, f.(X))\n",
    "    plot!(P, xp, abs.(p.(xp)), lw=2, label = \"p$N\", yaxis = (:log, [1e-2, 1e3]))\n",
    "end \n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the approximations **diverge**. This is called the Runge phenomenon. It is by no means an indicator that polynomials are poor basis functions for approximation. For example, let us use a least-squares fit w.r.t. exact function values on a fine grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = range(-1, stop=1, length=400)\n",
    "P = plot(xp, f.(xp), lw=2, label = \"f\")\n",
    "err = []\n",
    "NN = [10, 20, 30, 40]\n",
    "for N in NN\n",
    "    X = range(-1, stop=1, length=N)\n",
    "    p = polyfit(xp, f.(xp), N)\n",
    "    plot!(P, xp, p.(xp), lw=2, label = \"p$N\")\n",
    "    push!(err, norm(f.(xp) - p.(xp), Inf))\n",
    "end \n",
    "plot(P, plot(NN, err, lw=2, m=:o, yaxis = (:log,), label = \"\"), layout = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have recovered what looks like exponential convergence! Clearly there is something we need to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-2 Interpolation on Chebyshev Points\n",
    "\n",
    "In the lecture notes we have motivated the Chebyshev interpolation nodes \n",
    "$$\n",
    "  x_j = \\cos(\\pi j/ N)\n",
    "$$\n",
    "We can now check whether they fix the problem we had with equispaced nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebnodes(N) = [ cos(j*π/N) for j = N:-1:0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = range(-1, stop=1, length=400)\n",
    "P = plot(xp, f.(xp), lw=2, label = \"f\")\n",
    "NN = [10, 20, 30, 40]\n",
    "errcheb = []\n",
    "errfit = [] \n",
    "for N in NN\n",
    "    X = chebnodes(N)\n",
    "    pcheb = polyfit(X, f.(X))\n",
    "    plot!(P, xp, pcheb.(xp), lw=2, label = \"p$N\")\n",
    "    pfit = polyfit(xp, f.(xp), N)\n",
    "    push!(errcheb, norm(f.(xp) - pcheb.(xp), Inf))\n",
    "    push!(errfit, norm(f.(xp) - pfit.(xp), Inf))    \n",
    "end \n",
    "plot(P, \n",
    "     plot(NN, [errfit, errcheb], lw=2, m=:o, \n",
    "          label = [\"fit\", \"cheb\"], yaxis = (:log,)), \n",
    "     layout = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is excellent news. We will start from here and explore this in a lot more detail.\n",
    "\n",
    "Next, we observe another problem: evaluating the Chebyshev interpolant is numerically unstable! (At least how it is implemented in the `Polynomials.jl` package. We will return to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = 10:4:80\n",
    "errcheb = []\n",
    "for N in NN\n",
    "    X = chebnodes(N)\n",
    "    pcheb = polyfit(X, f.(X))\n",
    "    push!(errcheb, norm(f.(xp) - pcheb.(xp), Inf))\n",
    "end \n",
    "plot(NN, errcheb, lw=2, m=:o,  label = \"\", yaxis = (:log,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, we can still explore Chebyshev interpolation on some examples - as long as we remain aware of the limitation due to numerical instability. The following results look promising but the numerical stability is clearly a severe limitation for us. We will therefore explore the errors in a little more details after implementing the barycentric formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1(x) = 1 / (1+x^2)\n",
    "f2(x) = 1 / (1+25*x^2)\n",
    "f3(x) = sin(3*x)\n",
    "f4(x) = abs(sin(3*x))^3\n",
    "f5(x) = abs(x)\n",
    "f6(x) = sign(x) * abs(x)^(3/2)\n",
    "f7(x) = exp(-x^2)\n",
    "\n",
    "fall = [f1, f2, f3, f4, f5, f6, f7]\n",
    "nalg = [4,5,6]\n",
    "falg = fall[nalg]\n",
    "nana = [1, 2, 3, 7]\n",
    "fana = fall[nana]\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev Interpolation error for functions with exponential rates \n",
    "# ------------------------------------------------------------------\n",
    "# For these functions, the convergence is fast, so we don't hit \n",
    "# the numerical instability, at least for the fast converging ones\n",
    "# ------------------------------------------------------------------\n",
    "NN = 2:6:100\n",
    "xerr = range(-1, stop=1, length=1_000)\n",
    "P = plot(xaxis = (L\"N\",), \n",
    "         yaxis = (:log, L\"\\| f - I_N f\\|_{L^\\infty}\"), \n",
    "         legend=:right)\n",
    "for (f, n) in zip(fana, nana)\n",
    "    err = []\n",
    "    for N in NN \n",
    "        X = chebnodes(N)\n",
    "        p = polyfit(X, f.(X))\n",
    "        push!(err, norm(f.(xerr) - p.(xerr), Inf))\n",
    "    end\n",
    "    plot!(P, NN, err, lw=2, m=:o, ms=6, label = \"f$n\")\n",
    "end \n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev Interpolation error for functions with algebraic rates \n",
    "# ---------------------------------------------------------------\n",
    "# But for the more slowly converging tests, we get into the \n",
    "# regime of numerical instability very quickly\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "NN = (2).^(2:8)\n",
    "xerr = range(-1, stop=1, length=1_000)\n",
    "P = plot(xaxis = (:log, L\"N\"), \n",
    "         yaxis = (:log, L\"\\| f - I_N f\\|_{L^\\infty}\"), \n",
    "         legend=:top)\n",
    "for (f, n) in zip(falg, nalg)\n",
    "    err = []\n",
    "    for N in NN \n",
    "        X = chebnodes(N)\n",
    "        p = polyfit(X, f.(X))\n",
    "        push!(err, norm(f.(xerr) - p.(xerr), Inf))\n",
    "    end\n",
    "    plot!(P, NN, err, lw=2, m=:o, ms=6, label = \"f$n\")\n",
    "end \n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-3 Barycentric Formula\n",
    "\n",
    "In Sec. 4.4 we derived the baycentric interpolation formula and showed that one of its variants is numerically stable. As a matter of fact, both are stable but for the one we are using here this is a little more involved to prove. Here, we implement the specific formula for chebyshev points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Barycentric interpolation with a Chebyshev grid with N grid points.\n",
    "The interpolant is evaluated at points `x`.\n",
    "\"\"\"\n",
    "function bary(f::Function, N, x)\n",
    "    X = chebnodes(N)\n",
    "    F = f.(X)\n",
    "    return bary(F, x; X=X)\n",
    "end\n",
    "\n",
    "function bary(F::Vector, x; X = chebnodes(length(F)-1))\n",
    "    N = length(F)-1\n",
    "    p = 0.5 * ( F[1] ./ (x .- X[1]) + (-1)^N * F[N+1] ./(x .- X[N+1]) )\n",
    "    q = 0.5 * (1.0 ./ (x .- X[1]) + (-1)^N ./ (x .- X[N+1]))\n",
    "    for n = 1:N-1\n",
    "        p += (-1)^n * F[n+1] ./ (x .- X[n+1])\n",
    "        q += (-1)^n ./ (x .- X[n+1])\n",
    "    end \n",
    "    return p ./ q    \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "generate a grid on which to plot errors; this is chosen to avoid \n",
    "any grid points since barycentric interpolation is not defined \n",
    "on those.\n",
    "\"\"\"\n",
    "errgrid(Np) = range(-1+0.0123, stop=1-0.00321, length=Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to our opening example : no sign of instability, \n",
    "# and we  get precisely the prediced rate.\n",
    "# ------------------------------------------------------\n",
    "f(x) = 1/(1+25*x^2)\n",
    "xp = errgrid(1000)\n",
    "NN = 2:10:250\n",
    "err = [ norm(f.(xp) - bary(f, N, xp), Inf) for N = NN]\n",
    "pred = 1.5*exp.(-NN/5)\n",
    "plot(NN, [err, pred], lw=2, m=:o, \n",
    "    label=[\"err\", \"exp(-N/5)\"], yaxis = (:log,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The algebraically converging functions revisited, \n",
    "# this time with the predicted slopes \n",
    "# ---------------------------------------------------\n",
    "NN = (2).^(2:10)\n",
    "xerr = range(-1+0.00012, stop=1-0.000032, length=1_000)\n",
    "P = plot(xaxis = (:log, L\"N\"), \n",
    "         yaxis = (:log, L\"\\| f - I_N f\\|_{L^\\infty}\"), \n",
    "         legend=:bottom)\n",
    "for (f, n) in zip(falg, nalg)\n",
    "    err = [ norm(f.(xerr) - bary(f, N, xerr), Inf)  for N in NN ]\n",
    "    plot!(P, NN, err, lw=2, m=:o, ms=6, label = \"f$n\")\n",
    "end \n",
    "t = [NN[5], NN[8]]\n",
    "plot!(P, t, 1*t.^(-1.), lw=2, ls=:dash, c=:black, label=L\"\\sim N^{-1}, N^{-3/2}, N^{-3}\")\n",
    "plot!(P, t, t.^(-3/2), lw=2, ls=:dash, c=:black, label=\"\")\n",
    "plot!(P, t, 12*t.^(-3.), lw=2, ls=:dash, c=:black, label=\"\")\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the exponentially convergent functions revisited \n",
    "# f1, f2 get the prediced slopes, \n",
    "# f3, f7 are entire\n",
    "# ---------------------------------------------------\n",
    "NN = 2:4:46\n",
    "xerr = range(-1+0.00012, stop=1-0.000032, length=1_000)\n",
    "P = plot(xaxis = (L\"N\",), \n",
    "         yaxis = (:log, L\"\\| f - I_N f\\|_{L^\\infty}\"), \n",
    "         legend=:right)\n",
    "for (f, n) in zip(fana, nana)\n",
    "    err = [ norm(f.(xerr) - bary(f, N, xerr), Inf)  for N in NN ]\n",
    "    plot!(P, NN, err, lw=2, m=:o, ms=6, label = \"f$n\")\n",
    "end \n",
    "t = [NN[5], NN[8]]\n",
    "plot!(P, t, [exp.(-t), 0.1*exp.(-t/5)], \n",
    "      lw=2, ls=:dash, c=:black, \n",
    "      label=L\"\\sim e^{-N}, e^{-5N}\")\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-4 Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a \"special function\"\n",
    "\n",
    "Special functions are functions such as $\\exp(x), \\sin(x), \\cos(x), \\dots$, the Bessel functions, $\\Gamma$ function, Airy, and many more. Efficient and stable numerical evaluation of such functions is a mostly solved and well-understood problem. Nevertheless it is useful to see what kind of ideas might be involved. Here, we will just use polynomial interpolation of a Taylor series, but of course in practise one uses much more sophisticated techniques (more on that later).\n",
    "\n",
    "For simplicity, let us just consider the `sin` function. We can obtain a decent approxiation using Taylor series. Then we interpolate the Taylor series to get a Chebvyshev interpolant. Note that in principle we only need to evaluate `sin` in $[-\\pi/2, \\pi/2]$ as all other cases can be reduced to shifting and reflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsin(N, x) = imag(sum((im*x)^n / factorial(n) for n = 0:N))\n",
    "\n",
    "xx = range(-pi/2, stop=pi/2, length=1000)\n",
    "println(\"Taylor Expansion:\")\n",
    "for N in [7, 11, 15, 19]\n",
    "    errN = maximum(abs(sin(x) - tsin(N,x)) for x in xx) \n",
    "    println(\" N = $N => err = $errN\")\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that `tsin(20, x)` is a machine-precision approximation to `sin`. Now we can check how many points we need with a Chebyshev interpolant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal_tsin = s -> tsin(20, s*π/2)\n",
    "println(\"Chebyshev Interpolant:\")\n",
    "for N in [7, 9, 11, 15]\n",
    "    errN = norm(bary(scal_tsin, N, xx*2/π) - sin.(xx), Inf)\n",
    "    println(\" N = $N => err = $errN\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do even better by approximating only on the \n",
    "# interval [0, pi/2]\n",
    "xx = range(0+3.21e-12, stop=pi/2, length=333)\n",
    "scal_tsin1 = s -> sin((1 + s)*π/4)\n",
    "println(\"Chebyshev Interpolant:\")\n",
    "for N in [5, 8, 11, 13]\n",
    "    errN = norm(bary(scal_tsin1, N, xx*4/π.-1) - sin.(xx), Inf)\n",
    "    println(\" N = $N => err = $errN\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem like a small improvement, but a factor 2/3 in the evaluation cost would in fact represent a phenomenal gain in computing speed. The explanatio of this gain can be easily visualised: the taylor polynomial optimises the error in the origin while the Chebyshev interpolant distributes it more uniformly (but not uniformly enough, which is why it is not optimal; see later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 13\n",
    "xp = range(-pi/2, stop=pi/2, length=400)\n",
    "terr = tsin.(N, xp) - sin.(xp)\n",
    "cerr = bary(scal_tsin, N, xp*2/π) - sin.(xp)\n",
    "plot(xp, [terr, cerr], lw=2, label = [\"Taylor-error\", \"Chebyshev-error\"],\n",
    "         ylim = [-2e-13, 2e-13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Matrix Function \n",
    "\n",
    "Consider a discrete Laplacian-like matrix, \n",
    "$$\n",
    "    H = \\frac{1}{2}\\begin{pmatrix}\n",
    "        0 & 1      &        &        & \\\\ \n",
    "        1 & 0      & 1      &        &  \\\\ \n",
    "          & \\ddots & \\ddots & \\ddots &  \\\\ \n",
    "          &        &      1 &  0     & 1 \\\\ \n",
    "          &        &        &      1 & 0\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "One can readily see that $\\sigma(H) \\subset [-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseArrays\n",
    "Hfun(d) = spdiagm( -1 => ones(d-1)/2, 1 => ones(d-1)/2 )\n",
    "\n",
    "println(\"H(5) = \")\n",
    "display(Matrix(Hfun(5)))\n",
    "\n",
    "print(\"σ(H(100)) ⊂ \")\n",
    "println(extrema(eigvals(Matrix(Hfun(100)))))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to evaluate $f_\\beta(H)$ where $f_\\beta$ is the Fermi-Dirac function \n",
    "$$\n",
    "    f_\\beta(z) = \\Big( 1 + e^{\\beta z} \\Big)^{-1}\n",
    "$$\n",
    "We construct a Chebyshev interpolant, then use the Chebyshev transform to obtain the Chebyshev coefficients, which will then allow us to evaluate $f_\\beta(H)$ via the Chebyshev basis recursion as a series of Matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FFTW\n",
    "# we first implement the fast chebyshev transform \n",
    "\n",
    "revchebnodes(N) = [ cos(j*π/N) for j = 0:N ]\n",
    "\n",
    "function fct(F)\n",
    "    N = length(F)-1\n",
    "    G = [F; F[N:-1:2]]\n",
    "    Ĝ = real.(ifft(G))\n",
    "    return [Ĝ[1]; 2 * Ĝ[2:N]; Ĝ[N+1]]\n",
    "end \n",
    "\n",
    "\n",
    "function eval_chebpoly(F̃, x; ID = one(x))\n",
    "    N = length(F̃)-1\n",
    "    Told = ID\n",
    "    if N == 0; return Told * F̃[1]; end \n",
    "    Tnew = x \n",
    "    p = Told * F̃[1] + Tnew * F̃[2]\n",
    "    if N == 1; return p; end \n",
    "    for n = 2:N \n",
    "        Toldold = Told \n",
    "        Told = Tnew \n",
    "        Tnew = 2 * x * Told - Toldold\n",
    "        p += F̃[n+1] * Tnew\n",
    "    end \n",
    "    return p \n",
    "end\n",
    "\n",
    "f_fermi(β, x) = 1/(1 + exp(β*x))\n",
    "\n",
    "# a little test\n",
    "β = 10+rand()\n",
    "xx = range(-1, stop=1, length=1000)\n",
    "for N in [11, 21, 31, 41]\n",
    "    F = f_fermi.(β, revchebnodes(N))\n",
    "    F̃ = fct(F)\n",
    "    err = norm(f_fermi.(β, xx) - [eval_chebpoly(F̃, x) for x in xx])\n",
    "    println(\"N = $N => err = $err\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Matrix(Hfun(10))\n",
    "A = exp(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we can use this to evaluat a matrix function \n",
    "# ------------------------------------------------------\n",
    "\n",
    "# exact matrix function\n",
    "f_fermi_mat(β, H) = pinv(I + exp(β * Matrix(H)))\n",
    "    \n",
    "# using the chebyshev expansion \n",
    "function f_fermi_mat_cheb(β, H, N)\n",
    "    F = f_fermi.(β, revchebnodes(N))\n",
    "    F̃ = fct(F)\n",
    "    eval_chebpoly(F̃, H)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β, d = 10.0, 1000\n",
    "# ---------------\n",
    "A = Hfun(d)\n",
    "fH = f_fermi_mat(β, A)\n",
    "for N in [11, 21, 31, 41]\n",
    "    fH_N = f_fermi_mat_cheb(β, A, N)\n",
    "    err = norm(fH_N - fH, Inf)\n",
    "    println(\"N = $N => err = $err\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Runtime f_fermi_mat\")\n",
    "for n = 1:3 \n",
    "    @time f_fermi_mat(β, A)\n",
    "end\n",
    "println(\"Runtime f_fermi_mat_cheb, N = 21\")\n",
    "for n = 1:3 \n",
    "    @time f_fermi_mat_cheb(β, A, 11)\n",
    "end\n",
    "println(\"Runtime f_fermi_mat_cheb, N = 41\")\n",
    "for n = 1:3 \n",
    "    @time f_fermi_mat_cheb(β, A, 31)\n",
    "end\n",
    "println(\"\"\"Don't take these runtimes too seriously; there are a\n",
    "           lot of optimisations that we are missing in `eval_chebpoly`;\n",
    "           in particular a lot of the allocations can be avoided.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving a BVP \n",
    "\n",
    "As a final example, we look at how to solve boundary value problems using Chebyshev polynomials. There is an excellent Julia package, `ApproxFun.jl` that builds on the kind of ideas we discussed - and takes them much much further. So instead of putting together our own little toy code we will show how to use `ApproxFun.jl`.\n",
    "\n",
    "Consider the BVP \n",
    "$$\n",
    "    \\epsilon u'' + 6 (1-x^2). u' + u^2 = 1,  \n",
    "$$\n",
    "with boundary conditions $u(-1) = 1, u(1) = -1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ApproxFun\n",
    "x = Fun()  # defines the identity function x -> x\n",
    "N = u -> [u(-1)-1, \n",
    "          u(1)+0.5, \n",
    "          0.01 * u'' + 6 * (1-x^2) * u' + u^2 - 1]\n",
    "u = newton(N, 0*x)\n",
    "@show typeof(u)\n",
    "@show u.space\n",
    "@show length(u.coefficients)\n",
    "@show norm(N(u))\n",
    "plot(u; lw = 2, label = \"Solution to BVP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
